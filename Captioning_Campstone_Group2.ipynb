{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5a64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e423616b",
   "metadata": {},
   "source": [
    "Task1: Download the Flickr8K dataset.\n",
    "\n",
    "You will get it from Kaggle.\n",
    "\n",
    "After downloading check if you have around 8000 images and 40K around captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a0579b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/adityajn105/flickr8k\n",
      "Download complete! Files saved to: flickr8k_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Initialize Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Set output folder\n",
    "output_dir = 'flickr8k_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Dataset identifier from Kaggle URL\n",
    "dataset = 'adityajn105/flickr8k'\n",
    "\n",
    "# Download dataset\n",
    "api.dataset_download_files(dataset, path=output_dir, unzip=True)\n",
    "\n",
    "print(f'Download complete! Files saved to: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c23cc",
   "metadata": {},
   "source": [
    "**Task 2: Dump and save CLIP embeddings as .pt**\n",
    "\n",
    "Sample Code:\n",
    "\n",
    "```\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "```\n",
    "\n",
    "Load model and processor once\n",
    "```\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "def get_image_clip_embedding(image_path):\n",
    "    \"\"\"Returns the CLIP embedding for an image.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_image_features(**inputs)\n",
    "    return outputs.squeeze().numpy()\n",
    "\n",
    "def get_text_clip_embedding(text):\n",
    "    \"\"\"Returns the CLIP embedding for a text string.\"\"\"\n",
    "    inputs = processor(text=[text], return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_text_features(**inputs)\n",
    "    return outputs.squeeze().numpy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ed1695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.32.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.11.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading hf_xet-1.1.2-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.32.0-py3-none-any.whl (509 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Downloading hf_xet-1.1.2-cp37-abi3-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed hf-xet-1.1.2 huggingface-hub-0.32.0 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.52.3\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.7.0-cp312-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed sympy-1.14.0 torch-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9216ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dce51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "def get_image_clip_embedding(image_path):\n",
    "    # Returns the CLIP embedding for an image.\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_image_features(**inputs)\n",
    "    return outputs.squeeze().numpy()\n",
    "\n",
    "def get_text_clip_embedding(text):\n",
    "    # Returns the CLIP embedding for a text string.\n",
    "    inputs = processor(text=[text], return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_text_features(**inputs)\n",
    "    return outputs.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737b1d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.00014850e-02, -3.06078166e-01, -4.09442723e-01, -9.18519422e-02,\n",
       "       -1.19828582e-01,  1.38673306e-01,  1.24545962e-01, -2.88679540e-01,\n",
       "       -4.30587679e-01,  8.97039324e-02,  4.89853919e-01, -5.57267666e-02,\n",
       "        3.27696294e-01, -1.85254529e-01,  2.15534002e-01,  2.67497540e-01,\n",
       "       -8.22517276e-01, -3.04571480e-01, -2.21446212e-02,  1.75806001e-01,\n",
       "        7.08789453e-02,  6.94901049e-02,  1.36118814e-01, -9.67928320e-02,\n",
       "        1.29706666e-01,  3.53443503e-01,  6.15082681e-02,  5.37753642e-01,\n",
       "        1.09548107e-01, -3.11160207e-01,  3.29136699e-01,  1.04449280e-01,\n",
       "       -6.07568026e-03, -9.04831141e-02, -2.35322073e-01, -2.04668134e-01,\n",
       "        9.17144567e-02, -4.71669585e-02,  1.96631104e-01,  1.30874038e-01,\n",
       "       -1.11351445e-01,  2.89447784e-01, -5.81850529e-01,  4.38556910e-01,\n",
       "        1.89051971e-01,  1.94477707e-01,  3.57398093e-02, -2.32472092e-01,\n",
       "       -5.11886656e-01, -2.29162991e-01, -1.96215510e-03,  1.26233518e-01,\n",
       "       -2.17007361e-02, -4.17473376e-01, -4.10721079e-02,  7.83271641e-02,\n",
       "        1.57689005e-01, -1.96518749e-01,  1.54532328e-01, -2.48964727e-02,\n",
       "        5.26270568e-01,  4.87953871e-01, -1.19448528e-01,  1.11793280e-02,\n",
       "       -2.34919026e-01,  9.97659117e-02, -8.01234841e-02,  5.70645928e-01,\n",
       "       -3.86230648e-01, -3.01813394e-01, -1.20328091e-01, -5.37423491e-02,\n",
       "        1.40541017e-01,  2.66502500e-02, -1.09705716e-01, -2.68801600e-01,\n",
       "        6.45268023e-01,  2.48793066e-01, -1.53889954e-01,  2.72059739e-01,\n",
       "       -1.05399847e-01, -2.50342429e-01,  4.40791883e-02,  4.92391288e-01,\n",
       "       -3.74730527e-01,  3.57465625e-01, -1.47781372e-02,  7.75699764e-02,\n",
       "       -1.30594447e-01,  3.24567914e-01,  9.44158286e-02, -1.35406986e-01,\n",
       "       -8.94549847e-01,  2.28582695e-02, -2.59920359e-02, -8.21022168e-02,\n",
       "        7.27889314e-02,  5.45599759e-02,  1.45067021e-01, -2.37750784e-01,\n",
       "        1.05471730e-01,  3.55278045e-01,  6.07096404e-02, -3.23621035e-01,\n",
       "        4.53987658e-01,  1.16627663e-02, -1.11302704e-01,  4.65417564e-01,\n",
       "       -3.95290911e-01, -4.01163846e-01, -2.47597247e-01, -3.97306383e-02,\n",
       "        1.66123524e-01, -2.14062124e-01, -3.01844954e-01,  4.57015902e-01,\n",
       "       -3.25140148e-01, -1.21417403e-01,  4.84647989e-01,  7.07652569e-01,\n",
       "       -1.58701204e-02, -5.26558995e-01,  1.86343983e-01, -7.69603625e-02,\n",
       "        6.96672916e-01,  6.63269237e-02, -1.60096392e-01,  7.10570514e-02,\n",
       "       -1.13092020e-01,  1.09024838e-01,  1.46851629e-01,  2.61618406e-01,\n",
       "       -4.23283756e-01,  1.27583170e+00, -4.43970233e-01, -2.25341097e-01,\n",
       "        8.85498673e-02, -2.24433273e-01, -1.02395430e-01, -6.46607950e-02,\n",
       "        4.06792939e-01, -5.34902513e-01, -7.36031950e-01,  2.49601424e-01,\n",
       "       -6.19631112e-02,  1.82764634e-01,  2.34874189e-01,  2.01064348e-01,\n",
       "        4.90328968e-02, -3.96946847e-01,  1.88821048e-01, -2.09129453e-02,\n",
       "       -1.74993090e-02,  7.82508329e-02,  1.83984876e-01,  8.14985931e-02,\n",
       "       -1.00220226e-01,  1.56359449e-01,  1.44521743e-01,  1.99020445e-01,\n",
       "       -2.11139858e-01,  7.35029578e-04, -2.20009372e-01, -2.19159245e-01,\n",
       "       -9.70404744e-02, -2.63024718e-02,  3.19535553e-01,  2.03976691e-01,\n",
       "        1.00944705e-01, -1.44254774e-01,  1.75510690e-01, -2.53792316e-01,\n",
       "       -8.31519723e-01,  2.71367133e-02,  5.79710305e-02,  1.35242790e-01,\n",
       "        1.81247741e-02,  6.70249835e-02,  2.98054814e-01, -9.91100818e-02,\n",
       "       -1.40864313e-01, -3.12752753e-01, -1.47887290e-01,  2.45964155e-02,\n",
       "       -4.02877033e-01, -2.03856975e-02,  8.36998969e-02, -4.92978543e-01,\n",
       "       -2.69831151e-01,  6.00481749e-01,  2.16434494e-01, -1.18248209e-01,\n",
       "       -3.13704312e-01, -8.47337693e-02, -3.30430806e-01,  4.90175873e-01,\n",
       "       -3.96887362e-01,  4.08225536e-01, -2.56353676e-01, -1.42768562e-01,\n",
       "        3.11683655e-01, -1.95901901e-01,  2.01832935e-01, -2.47499794e-02,\n",
       "        2.19269216e-01, -5.02000302e-02, -1.88290954e-01,  2.44106963e-01,\n",
       "        2.16126531e-01,  3.53715062e-01,  3.84742141e-01, -5.98190725e-03,\n",
       "       -3.45164239e-01,  1.36617422e-01,  4.26098824e-01,  1.94147140e-01,\n",
       "        1.23546913e-01,  4.85166274e-02,  1.80986553e-01,  2.56449282e-02,\n",
       "        5.83582699e-01,  4.69341606e-01,  8.96097720e-03, -6.22259617e-01,\n",
       "       -6.85755491e-01, -3.73934835e-01, -1.32263944e-01, -9.62674469e-02,\n",
       "        1.09129995e-01, -3.10037941e-01, -1.67836711e-01, -7.91675150e-02,\n",
       "       -6.24733716e-02,  1.69829130e-01, -2.61126161e-02,  3.13296348e-01,\n",
       "       -2.36196801e-01, -9.54810679e-02, -1.35342658e-01,  1.18274748e-01,\n",
       "       -1.07093103e-01,  1.40797675e-01,  1.00712970e-01,  4.45257127e-03,\n",
       "       -2.35015512e-01,  1.85689300e-01, -1.88418195e-01,  3.30020279e-01,\n",
       "        9.98244733e-02, -5.49260527e-02, -5.80708444e-01, -3.50374505e-02,\n",
       "        6.08997494e-02,  2.89036870e-01,  4.34899554e-02, -5.47080487e-02,\n",
       "        4.38805968e-02, -3.98242235e-01, -2.21720077e-02,  5.87260008e-01,\n",
       "        2.06527442e-01, -1.98651522e-01,  2.15873033e-01, -1.12029910e-01,\n",
       "       -1.21401601e-01,  6.11730888e-02,  1.56514913e-01,  8.01765025e-02,\n",
       "       -7.11198151e-02, -1.80835575e-02, -2.33072579e-01,  2.79237106e-02,\n",
       "        1.99745268e-01,  2.00432807e-01, -9.92436856e-02,  2.32757524e-01,\n",
       "       -5.23837149e-01,  4.16791290e-01,  2.41035670e-02,  6.08631372e-02,\n",
       "        1.30291432e-01,  1.82145573e-02,  9.38170999e-02,  1.30215392e-01,\n",
       "       -6.72398880e-02,  3.96846741e-01, -3.52565199e-01,  1.83722287e-01,\n",
       "       -8.60826075e-02, -4.22396839e-01,  3.33381653e-01, -1.38524808e-02,\n",
       "        7.59630203e-02,  5.01173660e-02, -3.34692419e-01,  1.14286438e-01,\n",
       "       -3.40724260e-01,  1.25895441e-01, -3.00491780e-01, -2.62464255e-01,\n",
       "        4.61103141e-01, -3.61855775e-01, -1.02506816e-01, -3.89015198e-01,\n",
       "       -3.19920242e-01, -4.67154920e-01,  3.57177913e-01, -2.44823992e-01,\n",
       "        1.46375686e-01, -6.05869368e-02, -3.88516486e-01,  4.35374945e-01,\n",
       "        1.27937555e+00,  5.80139220e-01,  2.62253582e-02,  4.19963956e-01,\n",
       "       -8.66529197e-02, -4.46074516e-01,  9.47255045e-02, -8.66890326e-02,\n",
       "       -1.35417014e-01,  1.43923730e-01, -7.56332278e-03,  1.11921772e-01,\n",
       "       -2.37811878e-01,  1.96902856e-01,  2.80522406e-01, -7.86309987e-02,\n",
       "        2.39024758e-02, -5.68896890e-01,  1.97958171e-01,  6.47963583e-03,\n",
       "       -2.55980194e-01, -4.31141049e-01, -2.59190917e-01,  1.64487064e-01,\n",
       "       -4.69881356e-01,  1.68353632e-01,  5.51397502e-01,  1.35731697e-02,\n",
       "        2.39913017e-02, -9.51037854e-02, -3.27860638e-02, -3.12706232e-02,\n",
       "        4.21356142e-01, -6.48444355e-01,  5.14849484e-01,  2.66407043e-01,\n",
       "        2.57691853e-02,  5.68484783e-01,  1.79585248e-01, -1.52204409e-02,\n",
       "        1.29923284e-01, -1.33461475e-01, -2.72664011e-01, -4.27874088e-01,\n",
       "       -2.19709292e-01,  3.63813758e-01, -4.35543209e-02,  4.75601852e-01,\n",
       "       -8.21278617e-02, -4.53091711e-01,  5.98706782e-01,  1.10443354e-01,\n",
       "       -5.13997853e-01,  1.50055349e-01,  1.22618899e-01, -2.72716880e-01,\n",
       "        3.04345340e-02, -1.20355949e-01, -2.73341596e-01, -4.57692802e-01,\n",
       "       -1.58570766e-01,  1.03423625e-01,  1.07089698e-01,  3.39560986e-01,\n",
       "        2.21199155e-01, -9.73172337e-02, -2.88536772e-04,  7.61828348e-02,\n",
       "       -3.58521521e-01,  4.17773396e-01, -2.34645531e-01, -9.52373222e-02,\n",
       "       -7.96770602e-02, -1.49803907e-01,  1.24000013e-04,  2.37428606e-01,\n",
       "       -2.87579715e-01,  6.69776350e-02, -5.49391687e-01, -3.67719114e-01,\n",
       "        6.96243718e-03,  2.51998827e-02, -1.14698380e-01, -3.44559923e-02,\n",
       "        5.20579934e-01,  3.64210695e-01, -6.30858019e-02, -3.55599135e-01,\n",
       "        1.09556466e-01, -3.45225990e-01,  3.19951475e-01, -5.47273457e-02,\n",
       "       -2.55948082e-02, -2.01436713e-01,  5.25548995e-01, -1.16640098e-01,\n",
       "       -1.20380573e-01, -1.31709546e-01,  1.13820948e-01, -1.09005600e-01,\n",
       "        6.04856014e-01,  6.61978602e-01,  2.40601227e-01,  4.37110007e-01,\n",
       "       -1.53797373e-01,  3.13379377e-01,  1.81915537e-01, -2.18611628e-01,\n",
       "        1.96624994e-01, -6.94771558e-02, -1.87718719e-02, -5.49415834e-02,\n",
       "        8.28189254e-02, -2.82472402e-01, -2.73048639e-01,  1.02836810e-01,\n",
       "        1.91142648e-01,  2.57037520e-01, -4.42859083e-02, -7.17903674e-03,\n",
       "        3.75344545e-01, -8.77076760e-02, -3.22143078e-01, -2.79228508e-01,\n",
       "       -6.83837831e-02, -2.95140564e-01, -6.95319474e-01,  6.42823726e-02,\n",
       "       -2.01223210e-01, -3.92255157e-01,  4.75966126e-01, -1.48895517e-01,\n",
       "        2.32547611e-01,  5.32777011e-02,  8.80831480e-02, -9.71318185e-02,\n",
       "       -3.64640564e-01,  4.49024588e-01,  4.38145101e-02,  7.40508735e-02,\n",
       "       -2.08076388e-01,  7.42996573e-01, -2.56248593e-01, -4.61005241e-01,\n",
       "       -8.71854648e-03,  4.93906289e-02,  2.18134820e-01,  2.85264015e-01,\n",
       "        4.79688823e-01,  3.10561985e-01,  1.00225247e-02,  1.83188066e-01,\n",
       "        4.70250309e-01,  4.33149785e-02,  3.12202126e-01, -1.33381039e-01,\n",
       "       -1.72780886e-01,  1.19442910e-01, -2.65552461e-01,  1.99092805e-01,\n",
       "       -3.16528857e-01, -2.27185600e-02,  6.11985475e-02,  6.92550391e-02,\n",
       "        2.16301024e-01, -9.31499898e-02,  1.56767383e-01,  1.20728165e-02,\n",
       "        3.25534940e-02, -2.21777827e-01, -1.73104331e-02, -1.43510029e-01,\n",
       "       -4.71608341e-03,  6.74325377e-02,  5.41740060e-02, -4.18866962e-01,\n",
       "        3.00860524e-01, -1.31978646e-01,  3.80159408e-01,  3.53007019e-01,\n",
       "        2.73225784e-01,  9.29649472e-01,  4.99020040e-01, -3.45234066e-01,\n",
       "        2.95762420e-02, -1.98603094e-01, -3.15386951e-01,  2.17407018e-01,\n",
       "        1.26525730e-01,  2.69023180e-01, -1.31037802e-01,  1.79092035e-01,\n",
       "        4.38830614e-01, -1.69233367e-01, -1.09980285e-01,  4.99984771e-02,\n",
       "       -4.14970219e-02, -1.17750242e-01,  1.06962919e-01,  4.72475141e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_clip_embedding(\"A child in a pink dress is climbing up a set of stairs in an entry way .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
